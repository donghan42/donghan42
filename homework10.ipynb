{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "题目一、以鸢尾花数据集为例学习 SVM\n",
    "加载数据，划分鸢尾花数据集，训练集比例0.2，随机种子42\n",
    "创建并训练 SVM 模型，使用线性核函数，随机种子42（也可以自己调试、体验不同参数的作用，选择更好的值，注释明确即可）\n",
    "使用 Accuracy、Recall、F1 Score、Confusion Matri 这四个评估指标来评估实验效果\n",
    "SVM 基本概念\n",
    "将实例的特征向量（以二维为例）映射为空间中的一些点，如下图的实心点和空心点，它们属于不同的两类。SVM 的目的就是想要画出一条线，以“最好地”区分这两类点，以至如果以后有了新的点，这条线也能做出很好的分类。\n",
    "\n",
    "支持向量机（support vector machines，SVM）是一种二分类模型，它将实例的特征向量映射为空间中的一些点，SVM 的目的就是想要画出一条线，以 “最好地” 区分这两类点，以至如果以后有了新的点，这条线也能做出很好的分类。SVM 适合中小型数据样本、非线性、高维的分类问题。\n",
    "\n",
    "SVM 是有监督的学习模型，就是说我们需要先对数据打上标签，之后通过求解最大分类间隔来求解二分类问题，而对于多分类问题，可以组合多个 SVM 分类器来处理。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "x=iris.data #前四列属性\n",
    "y=iris.target #品种\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.8,random_state=42)\n",
    "\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "#训练模型\n",
    "svm_model.fit(x_train, y_train)\n",
    "# 使用训练好的模型进行预测\n",
    "y_pred = svm_model.predict(x_test)\n",
    "\n",
    "#评估模型\n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "recall=recall_score(y_test,y_pred,average=None)\n",
    "f1=f1_score(y_test,y_pred,average=None)\n",
    "confusion_mat=confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print('accuracy:',accuracy)\n",
    "print('recall:',recall)\n",
    "print('f1:',f1)\n",
    "print('confusion:',confusion_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "题目二、以新闻数据分类为例 学习朴素贝叶斯\n",
    "导入库与数据集，数据集的导入方式：from sklearn.datasets import fetch_20newsgroups\n",
    "查看类别标签、数据集的描述、数据样本\n",
    "将文本数据转换为词袋模型\n",
    "将数据集分为训练集和测试集，训练集比例0.2，随机种子42\n",
    "创建并训练朴素贝叶斯分类器\n",
    "使用 Accuracy、Recall、F1 Score 这三个评估指标来评估实验效果\n",
    "横坐标为 Predicted，纵坐标为 Actual，画出混淆矩阵Confusion Matrix\n",
    "朴素贝叶斯基本概念\n",
    "朴素贝叶斯（Naive Bayes）是一种基于贝叶斯定理的统计学分类方法。它被广泛应用于机器学习和数据挖掘领域，特别是在文本分类和垃圾邮件过滤等任务中取得了很好的效果。\n",
    "\n",
    "image\n",
    "\n",
    "聚类分析\n",
    "聚类是一种无监督学习的方法，旨在将数据集中的样本分组（或簇）成相似的集合，使得同一组内的样本相互之间更相似，而不同组之间的样本更不相似。\n",
    "\n",
    "聚类是发现数据内在结构的一种方法，它能够帮助我们理解数据的组织、发现隐藏的模式以及从数据中提取有用的信息。\n",
    "\n",
    "题目三、以鸢尾花数据集为例 学习k-means聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# 导入新闻数据集\n",
    "news = fetch_20newsgroups()\n",
    "# 查看类别标签\n",
    "print(\"类别标签:\", news.target_names)\n",
    "# 查看数据样本（这里查看第一条数据样本示例）\n",
    "print(\"数据样本示例:\", news.data[0])\n",
    "#将文本数据转化为词袋模型\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(news.data)\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,news.target, test_size=0.8, random_state=42)\n",
    "\n",
    "# 创建并训练朴素贝叶斯分类器（这里使用多项式朴素贝叶斯）\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred=nb_model.predict(X_test)\n",
    "\n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "recall=recall_score(y_test,y_pred,average=None)\n",
    "f1=f1_score(y_test,y_pred,average=None)\n",
    "confusion_mat=confusion_matrix(y_test,y_pred)\n",
    "print('accuracy:\\n',accuracy)\n",
    "print('recall:\\n',recall)\n",
    "print(\"f1:\\n\",f1)\n",
    "print('confusion_mat:\\n',confusion_mat)\n",
    "# 绘制混淆矩阵的可视化图\n",
    "plt.imshow(confusion_mat, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(news.target_names))\n",
    "plt.xticks(tick_marks, news.target_names, rotation=45)\n",
    "plt.yticks(tick_marks, news.target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "题目三、以鸢尾花数据集为例 学习k-means聚类\n",
    "导入数据集和聚类库\n",
    "使用k-means聚类，将数据分为3个簇，设置随机种子为0\n",
    "PCA 降维到2维空间后，输出可视化结果\n",
    "尝试先降维，再聚类，再输出可视化结果，比较两次的不同\n",
    "使用轮廓系数比较聚类效果\n",
    "绘制轮廓系数与聚类数的关系图\n",
    "轮廓系数（Silhouette Coefficient） 是一种用于度量数据点与其自身簇内数据的相似度与与最近的相邻簇的数据点的不相似度的指标。\n",
    "\n",
    "对于每个样本，计算它与同簇内所有其他点的平均距离（称为簇内平均距离，a）。\n",
    "\n",
    "对于每个样本，计算它与最近的不同簇内所有点的平均距离（称为簇间平均距离，b）。\n",
    "\n",
    "计算轮廓系数（S）：\n",
    "\n",
    "​image\n",
    "\n",
    "轮廓系数的取值范围在[-1, 1]之间：\n",
    "\n",
    "如果 S 接近1，表示样本与自身簇内的其他样本相似度高，与其他簇内的样本不相似，聚类效果好。\n",
    "如果 S 接近-1，表示样本与自身簇内的其他样本相似度低，与其他簇内的样本相似度高，聚类效果差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# 1. 导入数据集\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 2. 使用k-means聚类，将数据分为3个簇，设置随机种子为0\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "kmeans.fit(X)\n",
    "labels_original = kmeans.labels_\n",
    "\n",
    "# 3. PCA降维到2维空间后，输出可视化结果（原始数据先聚类后降维可视化）\n",
    "pca = PCA(n_components=2)\n",
    "X_pca_original = pca.fit_transform(X)\n",
    "\n",
    "plt.scatter(X_pca_original[:, 0], X_pca_original[:, 1], c=labels_original)\n",
    "plt.title(\"K-Means Clustering Result (Original Data)\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()\n",
    "\n",
    "# 4. 先降维，再聚类，再输出可视化结果\n",
    "X_pca = PCA(n_components=2).fit_transform(X)\n",
    "kmeans_pca = KMeans(n_clusters=3, random_state=0)\n",
    "kmeans_pca.fit(X_pca)\n",
    "labels_pca = kmeans_pca.labels_\n",
    "\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels_pca)\n",
    "plt.title(\"K-Means Clustering Result (After PCA)\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()\n",
    "\n",
    "# 5. 使用轮廓系数比较聚类效果\n",
    "score_original = silhouette_score(X, labels_original)\n",
    "score_pca = silhouette_score(X_pca, labels_pca)\n",
    "\n",
    "print(\"原始数据聚类的轮廓系数:\", score_original)\n",
    "print(\"先降维后聚类的轮廓系数:\", score_pca)\n",
    "\n",
    "# 6. 绘制轮廓系数与聚类数的关系图\n",
    "silhouette_scores = []\n",
    "cluster_range = range(2, 6)  # 尝试2到5个聚类数\n",
    "for n_clusters in cluster_range:\n",
    "    kmeans_loop = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans_loop.fit(X)\n",
    "    labels_loop = kmeans_loop.labels_\n",
    "    score_loop = silhouette_score(X, labels_loop)\n",
    "    silhouette_scores.append(score_loop)\n",
    "\n",
    "plt.plot(cluster_range, silhouette_scores)\n",
    "plt.title(\"Silhouette Coefficient vs. Number of Clusters\")\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Coefficient\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
